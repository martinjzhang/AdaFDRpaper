# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
# n_sample=20000
# p<0.000001: 46
# p<0.000010: 99
# p<0.000100: 215
# p<0.000500: 348

## method_init starts
# t_BH=0.003120, n_null=4476, n_alt=624
## Learning null distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[-0.144  -0.0804]
# Bump 0: w=0.2500
         mu=[0.5069 0.2551]
      sigma=[0.2904 0.1606]
# Bump 1: w=0.2500
         mu=[0.4654 0.7354]
      sigma=[0.285  0.1669]

## mixture_fit: learned parameters
# Slope: w=0.9078, a=[-0.1684 -0.012 ]
# Bump 0: w=0.0616
         mu=[0.5185 0.3523]
      sigma=[1.     0.1865]
# Bump 1: w=0.0307
         mu=[0.4903 0.5652]
      sigma=[1.     0.1742]

## Learning alternative distribution
## mixture_fit: initialization parameters
# Slope: w=0.5000, a=[0.3197 0.2807]
# Bump 0: w=0.2500
         mu=[0.2377 0.387 ]
      sigma=[0.1295 0.2501]
# Bump 1: w=0.2500
         mu=[0.7485 0.6221]
      sigma=[0.1423 0.2553]

## mixture_fit: learned parameters
# Slope: w=0.5710, a=[0.5051 0.349 ]
# Bump 0: w=0.2004
         mu=[0.2354 0.2429]
      sigma=[0.1034 0.1245]
# Bump 1: w=0.2286
         mu=[0.7453 0.7555]
      sigma=[0.101  0.1037]


## Test result with method_init
# Num of discovery: 798

## method_init finished

## rescale_mirror: before optimization
# quantile of t (1,25,75,99): [0.0949 0.1154 0.222  0.7508]
# gamma_pre=0.2024
# gamma_l=0.0204, gamma_u=0.0408, D_hat=873, FD_hat=102, alpha_hat=0.1168
# gamma_l=0.0204, gamma_u=0.0306, D_hat=817, FD_hat=84, alpha_hat=0.1028
# gamma_l=0.0204, gamma_u=0.0255, D_hat=783, FD_hat=76, alpha_hat=0.0971
# final output: gamma=0.0049

## choosing lambda0
## lambda0=206.3, D=798, FD_hat=81, alpha_hat=0.102
# lambda0=309.5, D_apr=744.3 (r err=0.067), FD_hat_apr=94.366 (r err=0.165)
# lambda0=412.6, D_apr=752.9 (r err=0.057), FD_hat_apr=87.933 (r err=0.086)
# lambda0=515.8, D_apr=761.1 (r err=0.046), FD_hat_apr=84.754 (r err=0.046)
# lambda0=618.9, D_apr=768.1 (r err=0.037), FD_hat_apr=83.053 (r err=0.025)
# lambda0=722.1, D_apr=773.9 (r err=0.030), FD_hat_apr=82.113 (r err=0.014)
# lambda0=825.3, D_apr=778.6 (r err=0.024), FD_hat_apr=81.593 (r err=0.007)
# lambda0=928.4, D_apr=782.3 (r err=0.020), FD_hat_apr=81.314 (r err=0.004)

## optimization paramter:
# n_itr=100, n_samp=20000, lambda0=928.0000, lambda1=100.0000

## method_single_fold: initialization
# Slope: a=[0.5051 0.349 ]
         b=-6.3208
# Bump 0: w=-4.3737
         mu=[0.2354 0.2429]
      sigma=[0.9762 0.8188]
# Bump 1: w=-4.0575
         mu=[0.7453 0.7555]
      sigma=[1.0238 1.1812]


## iteration 0: 
# n_rej=798, n_rej_apr=782.3, FD_hat=81, FD_hat_apr=81.3
# loss1=-0.0391, loss2=0.0154, FDP=0.1015, FDP_hat_apr=0.1039
# Slope: a=[0.4851 0.329 ]
         b=-6.3408
# Bump 0: w=-4.3937
         mu=[0.2554 0.2229]
      sigma=[0.9962 0.8388]
# Bump 1: w=-4.0775
         mu=[0.7253 0.7355]
      sigma=[1.0438 1.2012]

## iteration 20: 
# n_rej=805, n_rej_apr=787.7, FD_hat=76, FD_hat_apr=78.8
# loss1=-0.0394, loss2=0.0004, FDP=0.1093, FDP_hat_apr=0.1001
# Slope: a=[0.4583 0.3218]
         b=-6.3565
# Bump 0: w=-4.2900
         mu=[0.2278 0.2706]
      sigma=[0.82   0.8304]
# Bump 1: w=-4.0472
         mu=[0.6941 0.7212]
      sigma=[1.0711 1.1979]

## iteration 40: 
# n_rej=804, n_rej_apr=795.1, FD_hat=77, FD_hat_apr=79.7
# loss1=-0.0398, loss2=0.0011, FDP=0.1057, FDP_hat_apr=0.1003
# Slope: a=[0.4299 0.3142]
         b=-6.3766
# Bump 0: w=-4.2172
         mu=[0.2081 0.2496]
      sigma=[0.6635 0.8607]
# Bump 1: w=-3.9690
         mu=[0.7096 0.7036]
      sigma=[1.0844 1.2115]

## iteration 60: 
# n_rej=808, n_rej_apr=789.2, FD_hat=77, FD_hat_apr=77.3
# loss1=-0.0395, loss2=0.0000, FDP=0.1052, FDP_hat_apr=0.0980
# Slope: a=[0.3923 0.2957]
         b=-6.4079
# Bump 0: w=-4.1344
         mu=[0.1969 0.2383]
      sigma=[0.5822 0.8928]
# Bump 1: w=-3.9221
         mu=[0.7312 0.7219]
      sigma=[1.1096 1.241 ]

## iteration 80: 
# n_rej=828, n_rej_apr=807.6, FD_hat=79, FD_hat_apr=79.7
# loss1=-0.0404, loss2=0.0000, FDP=0.1147, FDP_hat_apr=0.0987
# Slope: a=[0.3716 0.2943]
         b=-6.4214
# Bump 0: w=-4.0347
         mu=[0.2025 0.2499]
      sigma=[0.5393 0.8924]
# Bump 1: w=-3.8811
         mu=[0.6987 0.7162]
      sigma=[1.1194 1.2605]

## rescale_mirror: after method_single_fold
# quantile of t (1,25,75,99): [0.002  0.0024 0.0063 0.0207]
# gamma_pre=1.0000
# gamma_l=0.7675, gamma_u=1.5351, D_hat=878, FD_hat=90, alpha_hat=0.1025
# gamma_l=0.7675, gamma_u=1.1513, D_hat=823, FD_hat=76, alpha_hat=0.0923
# gamma_l=0.9594, gamma_u=1.1513, D_hat=848, FD_hat=82, alpha_hat=0.0967
# gamma_l=1.0554, gamma_u=1.1513, D_hat=862, FD_hat=83, alpha_hat=0.0963
# gamma_l=1.1033, gamma_u=1.1513, D_hat=870, FD_hat=87, alpha_hat=0.1000
# gamma_l=1.1033, gamma_u=1.1273, D_hat=868, FD_hat=85, alpha_hat=0.0979
# gamma_l=1.1153, gamma_u=1.1273, D_hat=868, FD_hat=86, alpha_hat=0.0991
# final output: gamma=1.1243

## Test result with method_single_fold
# Num of discovery: 868
